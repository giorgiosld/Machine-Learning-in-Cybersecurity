import os
import joblib

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import confusion_matrix, f1_score


class MalwareClassifierEvaluator:
    """
    A class to evaluate different classifiers for malware classification using API traces.
    Attributes:
    X_train: Training data
    X_test: Testing data
    y_train: Training labels
    y_test: Testing labels
    """
    def __init__(self, X_train, X_test, y_train, y_test):
        """
        Initializes the MalwareClassifierEvaluator with the training and testing data.
        :param X_train: Training data
        :param X_test: Testing data
        :param y_train: Training labels
        :param y_test: Testing labels
        """
        self.X_train = X_train
        self.X_test = X_test
        self.y_train = y_train
        self.y_test = y_test
        self.classifiers = {
            'Logistic Regression': LogisticRegression(max_iter=1000),
            'K-Nearest Neighbors': KNeighborsClassifier(),
            'Decision Tree': DecisionTreeClassifier(),
            'Random Forest': RandomForestClassifier(
                                n_estimators=500,          # Number of trees
                                max_depth=20,              # Maximum depth of each tree
                                #min_samples_split=10,      # Minimum samples required to split a node
                                #min_samples_leaf=4,        # Minimum samples required in a leaf node
                                max_features='sqrt',       # Number of features to consider for the best split
                                #criterion='entropy',       # Use 'entropy' to measure split quality
                                class_weight='balanced',   # Handle class imbalance
                                #random_state=42            # Reproducibility
                            ),
            'Gradient Boosting': GradientBoostingClassifier(
                                n_estimators=500,          # Number of trees
                                learning_rate=0.02,         # Learning rate
                                max_depth=4,               # Maximum depth of each tree
                                #min_samples_split=10,      # Minimum samples to split an internal node
                                #min_samples_leaf=4,        # Minimum samples at a leaf node
                                subsample=0.8,             # Use 80% of data to fit each tree (adds randomness)
                                random_state=42            # Reproducibility
            )
        }
        self.best_model = None
        self.best_score = 0

    def train_and_evaluate(self):
        """Train each classifier and evaluate its performance."""
        for clf_name, clf in self.classifiers.items():
            print(f"Training {clf_name}...")
            # Train the classifier
            clf.fit(self.X_train, self.y_train)
            # Predict on the test set
            y_pred = clf.predict(self.X_test)
            # Compute the confusion matrix
            cm = confusion_matrix(self.y_test, y_pred)
            # Display the confusion matrix
            self.plot_confusion_matrix(cm, clf_name)

            # Compute F1 score using macro averaging (unweighted)
            f1_macro = f1_score(self.y_test, y_pred, average='macro')
            print(f"Average (Macro) F1 Score for {clf_name}: {f1_macro:.3f}")

            # Check if this is the best model so far
            if f1_macro > self.best_score:
                self.best_score = f1_macro
                self.best_model = clf

        # Save the best model to a file
        self.save_best_model()

    def save_best_model(self):
        """Save the best model using joblib."""
        if self.best_model:
            joblib.dump(self.best_model, 'best_model.joblib')
            print(f"Best model saved with F1-score: {self.best_score}")

    @staticmethod
    def _save_plot(path):
        """
        Private helper function to save the plot to the specified path
        :param path: The file path where the plot will be saved
        """
        save_dir = os.path.dirname(path)
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
        plt.savefig(path)
        plt.show()

    def plot_confusion_matrix(self, cm, clf_name):
        """Generate a heatmap for the confusion matrix.
        :param cm: Confusion matrix
        :param clf_name: Name of the classifier
        """
        class_labels = sorted(set(self.y_test))  # Extract unique class labels
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                    xticklabels=class_labels, yticklabels=class_labels)
        plt.title(f'Confusion Matrix for {clf_name}')
        plt.xlabel('Predicted Labels')
        plt.ylabel('True Labels')
        path = f"resources/cm_{clf_name.lower().replace(' ', '_')}.png"
        self._save_plot(path)

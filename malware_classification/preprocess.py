from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
import time

class Preprocessor:
    """
    A class to preprocess malware API traces for classification.

    Attributes:
    api_trace_file (str): Path to the file containing API traces
    label_file (str): Path to the file containing labels
    api_traces (list): List of API traces
    labels (list): List of labels
    vectorizer (CountVectorizer): CountVectorizer object for converting traces to feature vectors
    """

    def __init__(self, api_trace_file, label_file):
        """
        Initializes the Preprocessor with the paths to the API trace file and label file.
        :param api_trace_file:
        :param label_file:
        """
        self.api_trace_file = api_trace_file
        self.label_file = label_file
        self.api_traces = []
        self.labels = []
        self.vectorizer = None

    def load_data(self):
        """Loads the API traces and corresponding labels.
        """
        with open(self.api_trace_file, 'r') as f:
            for line in f:
                self.api_traces.append(line.strip())
        with open(self.label_file, 'r') as f:
            self.labels = [line.strip() for line in f]
        # with open(self.api_trace_file, 'r') as api_f, open(self.label_file, 'r') as label_f:
        #     self.api_traces = [line.strip() for line in api_f]
        #     self.labels = [line.strip() for line in label_f]

    @staticmethod
    def _remove_duplicates(trace):
        """Remove repeated API calls from a trace.
        :param trace: A string containing API calls separated by commas
        """
        api_calls = trace.split(',')
        return ','.join(api_calls[i] for i in range(len(api_calls)) if i == 0 or api_calls[i] != api_calls[i - 1])

    def preprocess_traces(self):
        """Preprocess the traces by removing duplicate calls."""
        for i, trace in enumerate(self.api_traces):
            self.api_traces[i] = self._remove_duplicates(trace)

    def vectorize_traces(self):
        """Convert traces into feature vectors using Bag of Words."""
        # Use CountVectorizer with binary=True to implement bag-of-words and ignore frequencies
        self.vectorizer = CountVectorizer(tokenizer=lambda x: x.split(','), binary=True)
        X = self.vectorizer.fit_transform(self.api_traces)
        return X.toarray()

    def split_data(self, X, y, test_size=0.3, random_state=42):
        """Splits the data into training and test sets.
        :param X: Feature vectors
        :param y: Labels
        :param test_size: Fraction of data to reserve for testing
        :param random_state: Seed for random number generator
        """
        return train_test_split(X, y, test_size=test_size, random_state=random_state)

    def preprocess(self):
        """Main preprocessing pipeline"""
        self.load_data()
        self.preprocess_traces()
        X = self.vectorize_traces()
        return self.split_data(X, self.labels)

if __name__ == '__main__':
    t = time.time()
    preprocessor = Preprocessor('api_trace.csv', 'apt_trace_labels.txt')
    X_train, X_test, y_train, y_test = preprocessor.preprocess()
    print(f'Total samples: {len(preprocessor.api_traces)}')
    print(f'Training samples: {len(X_train)}')
    print(f'Test samples: {len(X_test)}')
    print(f'Elapsed time: {time.time() - t:.2f} seconds')
import os

from sklearn.metrics import f1_score
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from tensorflow.keras.optimizers import Adam

from preprocess import Preprocessor

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # '0' = all messages, '1' = INFO, '2' = WARNING, '3' = ERROR

def create_lstm_model(vocab_size, embedding_dim, input_length, num_classes):
    """Creates an LSTM model."""
    model = Sequential()
    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length))
    model.add(LSTM(units=256, return_sequences=False))  # Adjust units as needed
    model.add(Dense(units=num_classes, activation='softmax'))
    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

def train_lstm_model(api_trace_file, label_file):
    """Trains the LSTM model on the given API traces and labels."""
    preprocessor = Preprocessor(api_trace_file, label_file)
    X_train, X_test, y_train, y_test = preprocessor.preprocess()

    # Ensure that labels are integers
    le = LabelEncoder()
    y_train = le.fit_transform(y_train)
    y_test = le.transform(y_test)

    # Since the preprocessor uses CountVectorizer, input is already vectorized.
    # We treat this input as embedding vectors.
    input_dim = X_train.shape[1]  # Number of features (from CountVectorizer)
    embedding_dim = 50  # Adjust the embedding dimension if needed
    input_length = X_train.shape[1]  # Input length is the number of features
    num_classes = len(set(y_train))  # Number of unique classes

    # Create the LSTM model
    model = create_lstm_model(input_dim, embedding_dim, input_length, num_classes)

    # Train the model
    model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))

    # Predict on the test set
    y_pred = model.predict(X_test)
    y_pred = y_pred.argmax(axis=1)  # Convert probabilities to class labels

    # Evaluate the F1 score using scikit-learn
    f1 = f1_score(y_test, y_pred, average='macro')
    print(f"LSTM Model F1 Score: {f1:.4f}")


if __name__ == '__main__':
    train_lstm_model('api_trace.csv', 'apt_trace_labels.txt')